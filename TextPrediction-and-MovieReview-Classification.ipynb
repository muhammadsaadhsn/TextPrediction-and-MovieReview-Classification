{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5b1d4fb-b1e6-4533-b154-5137ce77601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet, treebank\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ce6992bf-28f0-4626-adb5-6a5a2a5cfb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "reviews = data['review']\n",
    "sentiment = data['sentiment']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea8e99-6855-48fb-b2b5-c80929e5f4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7beae-89f8-4d84-901d-836cd0a69f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "755b0298-0e5b-41ed-af1d-d77b09038e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script performs text preprocessing on movie reviews.\n",
    "# It includes steps for lowercasing, cleaning text (removing HTML tags and special characters), \n",
    "# tokenization, and lemmatization. Additionally, it maintains a mapping between lemmatized words \n",
    "# and their original forms for future reference.\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word_mapping = {}\n",
    "\n",
    "def preprocess_text_with_mapping(text):\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'(<br\\s*/?>)|[^\\w\\s-]', '', text)  # Remove HTML tags and non-alphanumeric characters\n",
    "    tokens = word_tokenize(text)  # Tokenize the text into individual words\n",
    "    \n",
    "    lemmatized_tokens = []\n",
    "    for token in tokens:\n",
    "        lemma = lemmatizer.lemmatize(token)  # Lemmatize each token\n",
    "        lemmatized_tokens.append(lemma)\n",
    "        word_mapping[lemma] = token  # Map the lemmatized word to its original form\n",
    "\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply preprocessing to the 'review' column of the dataset\n",
    "data['tokens'] = data['review'].apply(preprocess_text_with_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "224f79f7-418d-4c16-9cb9-38a7f7a6a7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [one, of, the, other, reviewer, ha, mentioned,...\n",
       "1        [a, wonderful, little, production, the, filmin...\n",
       "2        [i, thought, this, wa, a, wonderful, way, to, ...\n",
       "3        [basically, there, a, family, where, a, little...\n",
       "4        [petter, matteis, love, in, the, time, of, mon...\n",
       "                               ...                        \n",
       "49995    [i, thought, this, movie, did, a, down, right,...\n",
       "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
       "49997    [i, am, a, catholic, taught, in, parochial, el...\n",
       "49998    [im, going, to, have, to, disagree, with, the,...\n",
       "49999    [no, one, expects, the, star, trek, movie, to,...\n",
       "Name: tokens, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7acad8e1-1906-4f5a-acc2-a3ae2d16fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Unigram, Bigram, Trigram Models \n",
    "\n",
    "unigram_model = FreqDist([word for tokens in data['tokens'] for word in tokens])\n",
    "bigram_model = FreqDist([bigram for tokens in data['tokens'] for bigram in ngrams(tokens, 2)])\n",
    "trigram_model = FreqDist([trigram for tokens in data['tokens'] for trigram in ngrams(tokens, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10717256-08f7-45f9-90ab-60835f46ea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 650834, 'a': 409471, 'and': 319819, 'of': 288073, 'to': 266317, 'is': 210100, 'it': 199366, 'in': 183211, 'i': 145581, 'this': 145536, ...})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "475af948-3c7f-4387-848f-f3bb33fe3c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('of', 'the'): 76983, ('in', 'the'): 49633, ('this', 'movie'): 29796, ('is', 'a'): 27107, ('and', 'the'): 26279, ('the', 'film'): 25454, ('to', 'the'): 23619, ('to', 'be'): 23154, ('the', 'movie'): 22981, ('this', 'film'): 20637, ...})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f8107e9-0ec6-472f-9f21-4a5e1d053ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('one', 'of', 'the'): 9621, ('of', 'the', 'film'): 5078, ('this', 'movie', 'is'): 4852, ('a', 'lot', 'of'): 4650, ('this', 'is', 'a'): 4370, ('of', 'the', 'movie'): 4249, ('some', 'of', 'the'): 3676, ('is', 'one', 'of'): 3539, ('the', 'film', 'is'): 3337, ('this', 'film', 'is'): 3228, ...})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bcef43e-dbea-4cdd-b7be-c2da9d280657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function predicts the next word in a sequence using unigram, bigram, and trigram models.\n",
    "# It lemmatizes the previous words for consistency with the model and then uses the n-grams to predict the most probable next word.\n",
    "# If no suitable n-gram is found, it falls back on the unigram model. The final predicted word is mapped back to its original form using a word mapping dictionary.\n",
    "\n",
    "def predict_next_word_ngram(prev_words):\n",
    "    # Lemmatize previous words for consistency with the n-gram models\n",
    "    prev_words = [lemmatizer.lemmatize(word) for word in prev_words]\n",
    "    \n",
    "    # If no previous words are provided, predict the most frequent word from the unigram model\n",
    "    if len(prev_words) == 0:\n",
    "        predicted_word = unigram_model.max()\n",
    "        \n",
    "    # If two previous words are provided, search for trigrams that match the first two words\n",
    "    elif len(prev_words) == 2:\n",
    "        ngrams_with_prev = {key: value for key, value in trigram_model.items() if key[:2] == tuple(prev_words)}\n",
    "        if ngrams_with_prev:\n",
    "            predicted_word = max(ngrams_with_prev, key=ngrams_with_prev.get)[-1]  # Predict based on the most frequent trigram\n",
    "        else:\n",
    "            predicted_word = unigram_model.max()  # Fall back to the unigram model if no trigram is found\n",
    "            \n",
    "    # If only one previous word is provided, search for bigrams that match the last word\n",
    "    elif len(prev_words) == 1:\n",
    "        ngrams_with_prev = {key: value for key, value in bigram_model.items() if key[0] == prev_words[-1]}\n",
    "        if ngrams_with_prev:\n",
    "            predicted_word = max(ngrams_with_prev, key=ngrams_with_prev.get)[-1]  # Predict based on the most frequent bigram\n",
    "        else:\n",
    "            predicted_word = unigram_model.max()  # Fall back to the unigram model if no bigram is found\n",
    "    else:\n",
    "        predicted_word = unigram_model.max()  # General fallback to unigram model if something unexpected happens\n",
    "    \n",
    "    # Map the lemmatized predicted word back to its original form, if it exists in the word mapping\n",
    "    return word_mapping.get(predicted_word, predicted_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f640fa5-e0ed-4fbb-9699-8e46385823d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "is\n",
      "anyone\n"
     ]
    }
   ],
   "source": [
    "predicted_word = predict_next_word_ngram([''])\n",
    "print(predicted_word)\n",
    "\n",
    "predicted_word = predict_next_word_ngram(['movies'])\n",
    "print(predicted_word)\n",
    "\n",
    "predicted_word = predict_next_word_ngram(['please', 'can'])\n",
    "print(predicted_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489ea02-b0a9-4d75-9b5c-a39a0017e077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499fdd3d-885f-4912-abc5-31ff48156b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec238f36-d339-4281-b8d3-e7f37ddbbf7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c13d70-1869-4bd6-ade3-eff2a0170087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bae1ab52-671c-447d-adce-58d1442ab926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function preprocesses text for classification by lowercasing, removing HTML tags and special characters,\n",
    "# tokenizing, lemmatizing words, and filtering out stop words (common words like \"the\", \"is\", \"and\").\n",
    "# The preprocessed text is returned as a list of meaningful words, ready for use in the classification model.\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text_for_classifier(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'(<br\\s*/?>)|[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    meaningful_words = [word for word in lemmatized_tokens if word not in stop_words]\n",
    "    return meaningful_words\n",
    "\n",
    "\n",
    "data['tokens'] = data['review'].apply(preprocess_text_for_classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2805a-a791-430a-9241-0d35d98d267b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "439f1ff2-af77-4aad-9442-97815f245e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Prior for postive and negative\n",
    "\n",
    "positive_reviews = data[data['sentiment'] == 'positive']\n",
    "negative_reviews = data[data['sentiment'] == 'negative']\n",
    "\n",
    "prior_positive = len(positive_reviews) / len(data)\n",
    "prior_negative = len(negative_reviews) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd369aed-04f1-4f02-a63d-e60e3ebe18b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Positive: 0.5, Prior Negative: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prior Positive: {prior_positive}, Prior Negative: {prior_negative}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a6f955d-621a-4db1-ae51-3deddf0fcfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram, Bigram, and Trigram Models for Positive Reviews\n",
    "positive_unigram_model = FreqDist([word for tokens in data[data['sentiment'] == 'positive']['tokens'] for word in tokens])\n",
    "positive_bigram_model = FreqDist(ngrams([word for tokens in data[data['sentiment'] == 'positive']['tokens'] for word in tokens], 2))\n",
    "positive_trigram_model = FreqDist(ngrams([word for tokens in data[data['sentiment'] == 'positive']['tokens'] for word in tokens], 3))\n",
    "\n",
    "# Unigram, Bigram, and Trigram Models for Negative Reviews\n",
    "negative_unigram_model = FreqDist([word for tokens in data[data['sentiment'] == 'negative']['tokens'] for word in tokens])\n",
    "negative_bigram_model = FreqDist(ngrams([word for tokens in data[data['sentiment'] == 'negative']['tokens'] for word in tokens], 2))\n",
    "negative_trigram_model = FreqDist(ngrams([word for tokens in data[data['sentiment'] == 'negative']['tokens'] for word in tokens], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b9fc2b9-19fd-402e-b104-87a92664d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(review):\n",
    "    tokens = preprocess_text_for_classifier(review)\n",
    "    positive_log_prob = math.log(prior_positive)\n",
    "    negative_log_prob = math.log(prior_negative)\n",
    "    \n",
    "    # Unigram Likelihood for Positive and Negative Reviews\n",
    "    for token in tokens:\n",
    "        positive_log_prob += math.log((positive_unigram_model[token] + 1) / (sum(positive_unigram_model.values()) + len(positive_unigram_model)))\n",
    "        negative_log_prob += math.log((negative_unigram_model[token] + 1) / (sum(negative_unigram_model.values()) + len(negative_unigram_model)))\n",
    "    \n",
    "    # Bigram Likelihood for Positive and Negative Reviews\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "    for bigram in bigrams:\n",
    "        positive_log_prob += math.log((positive_bigram_model[bigram] + 1) / (sum(positive_bigram_model.values()) + len(positive_bigram_model)))\n",
    "        negative_log_prob += math.log((negative_bigram_model[bigram] + 1) / (sum(negative_bigram_model.values()) + len(negative_bigram_model)))\n",
    "\n",
    "    return 'positive' if positive_log_prob > negative_log_prob else 'negative'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "97a9e5f4-b0d7-45f8-aa4e-c326fa2a5354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The movie was fantastic and well-directed. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The movie was terrible and boring. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: I loved the acting but hated the script. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: This was a waste of time. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: I loved this movie. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: This is my favourite movie. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The performances were outstanding, but the plot was confusing. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Great visuals and an even better storyline. I highly recommend it! \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: It was slow and tedious, definitely not my kind of movie. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A beautifully crafted story with excellent acting. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The dialogue felt forced and unnatural, making it hard to enjoy. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Absolutely loved the character development. I could watch it again! \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The soundtrack was amazing, but everything else was mediocre at best. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: One of the best films I've seen in a while, thoroughly enjoyed it. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Way too long and filled with unnecessary subplots. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A heartwarming story that resonates deeply. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Disappointing from start to finish, couldn't wait for it to end. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: The special effects were top-notch, truly breathtaking. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Not worth the hype. I found it pretty dull and predictable. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A thrilling ride with unexpected twists and turns! \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The acting felt wooden, and the direction was uninspired. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: It was an emotional rollercoaster that kept me engaged. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: This movie had no redeeming qualities, a total flop. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: An incredible performance by the lead actor, so powerful and moving. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The pacing was all over the place, which ruined the experience for me. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: It had a strong message and delivered it with grace and style. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: I was bored throughout, nothing exciting ever happened. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Visually stunning with a gripping narrative. Highly recommend! \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: A cliché story with no originality, just a waste of time. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: I felt connected to the characters, and the storyline was heartfelt. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Horrible editing and choppy transitions made it hard to follow. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A must-watch for anyone who enjoys thought-provoking films. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Predictable plot and weak acting, not impressive. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: An excellent blend of action, drama, and humor. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The movie tried too hard to be funny, but it fell flat. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: An absolute masterpiece that left me speechless. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Overhyped and disappointing, I expected so much more. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A touching story with relatable characters and a powerful message. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: It dragged on forever with no real purpose. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: I couldn't stop smiling throughout the whole film. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Completely uninspired and forgettable. I don't recommend it. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: The humor was spot on, and the dialogue felt natural. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: This is one of the worst movies I’ve ever seen. Don’t waste your time. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: The plot was intriguing and kept me guessing until the end. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: I didn’t understand the hype; it was pretty boring. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: The romance was beautifully portrayed and felt genuine. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The action sequences were a mess and hard to follow. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A visually captivating film with deep emotional layers. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: I didn't care for the characters or the story at all. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A delightful movie with an uplifting ending. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: I struggled to stay awake through the entire thing. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Such a heartwarming and inspiring film. Highly recommended! \u001b[92mPOSITIVE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This script processes a list of movie reviews, classifies each review as either \"positive\" or \"negative\",\n",
    "# and displays the review with a corresponding colored label using ANSI escape codes.\n",
    "# It also stores the predicted labels and actual labels for further analysis or evaluation purposes.\n",
    "\n",
    "# ANSI escape codes for colors\n",
    "class Colors:\n",
    "    GREEN = '\\033[92m'  # Green\n",
    "    RED = '\\033[91m'    # Red\n",
    "    ENDC = '\\033[0m'    # Reset color\n",
    "    \n",
    "# Test dataset containing movie reviews and their actual sentiment labels\n",
    "TestData = [\n",
    "    {\"review\": \"The movie was fantastic and well-directed.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The movie was terrible and boring.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"I loved the acting but hated the script.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"This was a waste of time.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"I loved this movie.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"This is my favourite movie.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The performances were outstanding, but the plot was confusing.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"Great visuals and an even better storyline. I highly recommend it!\", \"label\": \"positive\"},\n",
    "    {\"review\": \"It was slow and tedious, definitely not my kind of movie.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A beautifully crafted story with excellent acting.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The dialogue felt forced and unnatural, making it hard to enjoy.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"Absolutely loved the character development. I could watch it again!\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The soundtrack was amazing, but everything else was mediocre at best.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"One of the best films I've seen in a while, thoroughly enjoyed it.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Way too long and filled with unnecessary subplots.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A heartwarming story that resonates deeply.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Disappointing from start to finish, couldn't wait for it to end.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"The special effects were top-notch, truly breathtaking.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Not worth the hype. I found it pretty dull and predictable.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A thrilling ride with unexpected twists and turns!\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The acting felt wooden, and the direction was uninspired.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"It was an emotional rollercoaster that kept me engaged.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"This movie had no redeeming qualities, a total flop.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"An incredible performance by the lead actor, so powerful and moving.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The pacing was all over the place, which ruined the experience for me.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"It had a strong message and delivered it with grace and style.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"I was bored throughout, nothing exciting ever happened.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"Visually stunning with a gripping narrative. Highly recommend!\", \"label\": \"positive\"},\n",
    "    {\"review\": \"A cliché story with no originality, just a waste of time.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"I felt connected to the characters, and the storyline was heartfelt.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Horrible editing and choppy transitions made it hard to follow.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A must-watch for anyone who enjoys thought-provoking films.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Predictable plot and weak acting, not impressive.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"An excellent blend of action, drama, and humor.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The movie tried too hard to be funny, but it fell flat.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"An absolute masterpiece that left me speechless.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Overhyped and disappointing, I expected so much more.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A touching story with relatable characters and a powerful message.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"It dragged on forever with no real purpose.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"I couldn't stop smiling throughout the whole film.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Completely uninspired and forgettable. I don't recommend it.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"The humor was spot on, and the dialogue felt natural.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"This is one of the worst movies I’ve ever seen. Don’t waste your time.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"The plot was intriguing and kept me guessing until the end.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"I didn’t understand the hype; it was pretty boring.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"The romance was beautifully portrayed and felt genuine.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The action sequences were a mess and hard to follow.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A visually captivating film with deep emotional layers.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"I didn't care for the characters or the story at all.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A delightful movie with an uplifting ending.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"I struggled to stay awake through the entire thing.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"Such a heartwarming and inspiring film. Highly recommended!\", \"label\": \"positive\"},\n",
    "]\n",
    "\n",
    "\n",
    "# Lists to store predicted and actual labels for evaluation\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "# Iterating through the test data, classifying the reviews, and displaying them with colored labels\n",
    "for item in TestData:\n",
    "    actual_labels.append(item['label'])  # Store the actual label\n",
    "    review = item['review']\n",
    "    result = classify_review(review.lower())  # Classify the review using your classification function\n",
    "    \n",
    "    # Determine color based on the predicted label (positive/negative)\n",
    "    if result == \"positive\":\n",
    "        predicted_labels.append('positive')\n",
    "        color = Colors.GREEN\n",
    "    else:\n",
    "        predicted_labels.append('negative')\n",
    "        color = Colors.RED\n",
    "    \n",
    "    # Print the review with the predicted label in the corresponding color\n",
    "    print(f\"Review: {review} {color}{result.upper()}{Colors.ENDC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c438f-bda4-48d0-809b-1f0594c4f6db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c3f50-dc9a-4b71-ad6d-b6e7eb8b7802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00df076b-674e-49e6-9f92-6c3ad618b623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.15384615384616%\n",
      "Precision: 1.0\n",
      "Recall: 0.9230769230769231\n",
      "F1 Score: 0.9600000000000001\n"
     ]
    }
   ],
   "source": [
    "from nltk import ConfusionMatrix\n",
    "\n",
    "# Function to calculate confusion matrix values: True Positives (TP), True Negatives (TN),\n",
    "# False Positives (FP), and False Negatives (FN)\n",
    "def calculate_confusion_matrix(actual_labels, predicted_labels, positive_label='positive'):\n",
    "    # Initialize counts for confusion matrix\n",
    "    TP = TN = FP = FN = 0\n",
    "    \n",
    "    # Loop over actual and predicted labels simultaneously\n",
    "    for actual, predicted in zip(actual_labels, predicted_labels):\n",
    "        if actual == positive_label and predicted == positive_label:\n",
    "            TP += 1  # True Positive: both actual and predicted labels are positive\n",
    "        elif actual == positive_label and predicted != positive_label:\n",
    "            FN += 1  # False Negative: actual is positive but predicted is not\n",
    "        elif actual != positive_label and predicted == positive_label:\n",
    "            FP += 1  # False Positive: actual is not positive but predicted is positive\n",
    "        else:\n",
    "            TN += 1  # True Negative: both actual and predicted labels are not positive\n",
    "    \n",
    "    return TP, TN, FP, FN  # Return the counts of TP, TN, FP, FN\n",
    "\n",
    "# Function to calculate accuracy score\n",
    "# Formula: Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "def accuracy_score_nltk(TP, TN, FP, FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Function to calculate precision\n",
    "# Formula: Precision = TP / (TP + FP)\n",
    "def precision_score_nltk(TP, FP):\n",
    "    return TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "# Function to calculate recall\n",
    "# Formula: Recall = TP / (TP + FN)\n",
    "def recall_score_nltk(TP, FN):\n",
    "    return TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "# Function to calculate F1 Score\n",
    "# Formula: F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "def f1_score_nltk(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Calculate confusion matrix counts (True Positives, True Negatives, False Positives, False Negatives)\n",
    "TP, TN, FP, FN = calculate_confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "accuracy = accuracy_score_nltk(TP, TN, FP, FN)\n",
    "precision = precision_score_nltk(TP, FP)\n",
    "recall = recall_score_nltk(TP, FN)\n",
    "f1 = f1_score_nltk(precision, recall)\n",
    "\n",
    "# Print the results of the evaluation metrics\n",
    "print(f'Accuracy: {accuracy*100}%')  # Display accuracy as a percentage\n",
    "print(f'Precision: {precision}')     # Display precision\n",
    "print(f'Recall: {recall}')           # Display recall\n",
    "print(f'F1 Score: {f1}')             # Display F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37ad6a-12d3-4d7a-8645-a89cd4b647bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf12bd-3424-4bf9-8a30-82b9de2953a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5bf762-5424-4dca-93d1-524619d6f014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11db17-78cf-446b-99eb-a8e91875fcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944fa347-f90e-4c01-880d-faa1fffbed88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b290c9e-cd7d-4c83-9a5b-bee2042750f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1132246-01ba-47cb-b824-a136afffdbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59e51f04-f56f-4445-98a9-7eb7dcfddcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################\n",
    "###############################################################################################################################################\n",
    "###############################################################################################################################################\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc853844-4248-4e91-86a1-f9e8ee07f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "04dc1226-e290-4a94-979a-48b44b3e9cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_trigram(trigram_model, start_words, sentence_length):\n",
    "    current_words = start_words\n",
    "    sentence = list(current_words)\n",
    "    \n",
    "    for _ in range(sentence_length - len(current_words)):  \n",
    "        possible_trigrams = [trigram for trigram in trigram_model if trigram[:2] == tuple(current_words)]\n",
    "        \n",
    "        if possible_trigrams:\n",
    "            next_trigram = random.choice(possible_trigrams)\n",
    "            next_word = next_trigram[2]\n",
    "            sentence.append(next_word)\n",
    "            current_words = (sentence[-2], sentence[-1])  # Update to the last two words\n",
    "        else:\n",
    "            break    # Stop if no more trigrams match the current sequence\n",
    "    \n",
    "    return ' '.join(sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e10d1-e8aa-463a-a49e-5d026e439469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentenc: faux documentary fashion in one \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: film photographer finished his long \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: lie become increasingly formulaic this \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: martin schneider nina hagen trivia \u001b[91mNEGATIVE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    start_words = list(random.choice(list(bigram_model.keys())))\n",
    "    generated_sentence = generate_sentence_trigram(trigram_model, start_words, sentence_length=5)\n",
    "    result = classify_review(generated_sentence.lower())  # Classify the review using your classification function\n",
    "        \n",
    "    if result == \"positive\":\n",
    "        color = Colors.GREEN\n",
    "    else:\n",
    "        color = Colors.RED\n",
    "    \n",
    "    print(f\"Generated sentenc: {generated_sentence} {color}{result.upper()}{Colors.ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c17b9-6b85-4af5-89ce-55f5b98114bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate confusion matrix counts (True Positives, True Negatives, False Positives, False Negatives)\n",
    "# TP, TN, FP, FN = calculate_confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "# accuracy = accuracy_score_nltk(TP, TN, FP, FN)\n",
    "# precision = precision_score_nltk(TP, FP)\n",
    "# recall = recall_score_nltk(TP, FN)\n",
    "# f1 = f1_score_nltk(precision, recall)\n",
    "\n",
    "# # Print the results of the evaluation metrics\n",
    "# print(f'Accuracy: {accuracy*100}%')  # Display accuracy as a percentage\n",
    "# print(f'Precision: {precision}')     # Display precision\n",
    "# print(f'Recall: {recall}')           # Display recall\n",
    "# print(f'F1 Score: {f1}')             # Display F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9c12e39a-b3ef-40be-b2de-a87989a0d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################################\n",
    "###############################################################################################################################################\n",
    "###############################################################################################################################################\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143f4a0-ecd6-438e-83a5-5db43897366b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ea9c2-6e9e-4e41-a708-deaf8989bc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78dc460-c653-40b4-b162-2249f8935389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
