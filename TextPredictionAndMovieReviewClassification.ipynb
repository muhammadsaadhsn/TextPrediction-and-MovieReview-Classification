{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8017dc6e-dd40-486a-b709-157ff544ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet, treebank\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1047393-dabe-49df-9ae0-9b454bca05fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "reviews = data['review']\n",
    "sentiment = data['sentiment']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13222aa-7b59-4d13-83e0-e6ec056a7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script performs text preprocessing on movie reviews.\n",
    "# It includes steps for lowercasing, cleaning text (removing HTML tags and special characters), \n",
    "# tokenization, and lemmatization. Additionally, it maintains a mapping between lemmatized words \n",
    "# and their original forms for future reference.\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word_mapping = {}\n",
    "\n",
    "def preprocess_text_with_mapping(text):\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'(<br\\s*/?>)|[^\\w\\s-]', '', text)  # Remove HTML tags and non-alphanumeric characters\n",
    "    tokens = word_tokenize(text)  # Tokenize the text into individual words\n",
    "    \n",
    "    lemmatized_tokens = []\n",
    "    for token in tokens:\n",
    "        lemma = lemmatizer.lemmatize(token)  # Lemmatize each token\n",
    "        lemmatized_tokens.append(lemma)\n",
    "        word_mapping[lemma] = token  # Map the lemmatized word to its original form\n",
    "\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply preprocessing to the 'review' column of the dataset\n",
    "data['tokens'] = data['review'].apply(preprocess_text_with_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20256ae8-7838-47db-b1e1-749eadb4e933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [one, of, the, other, reviewer, ha, mentioned,...\n",
       "1        [a, wonderful, little, production, the, filmin...\n",
       "2        [i, thought, this, wa, a, wonderful, way, to, ...\n",
       "3        [basically, there, a, family, where, a, little...\n",
       "4        [petter, matteis, love, in, the, time, of, mon...\n",
       "                               ...                        \n",
       "49995    [i, thought, this, movie, did, a, down, right,...\n",
       "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
       "49997    [i, am, a, catholic, taught, in, parochial, el...\n",
       "49998    [im, going, to, have, to, disagree, with, the,...\n",
       "49999    [no, one, expects, the, star, trek, movie, to,...\n",
       "Name: tokens, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6373c069-cf12-42bc-81d7-e8606ffd4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_model_freq = FreqDist([word for tokens in data['tokens'] for word in tokens])\n",
    "bigram_model_freq = FreqDist([bigram for tokens in data['tokens'] for bigram in ngrams(tokens, 2)])\n",
    "trigram_model_freq = FreqDist([trigram for tokens in data['tokens'] for trigram in ngrams(tokens, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14bdd5c5-c8aa-49af-b985-9fb7b33d8653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 650834, 'a': 409471, 'and': 319819, 'of': 288073, 'to': 266317, 'is': 210100, 'it': 199366, 'in': 183211, 'i': 145581, 'this': 145536, ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_model_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f22004cc-8b60-4e68-b2f9-1cc22b2ed044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('of', 'the'): 76983, ('in', 'the'): 49633, ('this', 'movie'): 29796, ('is', 'a'): 27107, ('and', 'the'): 26279, ('the', 'film'): 25454, ('to', 'the'): 23619, ('to', 'be'): 23154, ('the', 'movie'): 22981, ('this', 'film'): 20637, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfbdcd9-3ede-475f-9026-52de2afab75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('one', 'of', 'the'): 9621, ('of', 'the', 'film'): 5078, ('this', 'movie', 'is'): 4852, ('a', 'lot', 'of'): 4650, ('this', 'is', 'a'): 4370, ('of', 'the', 'movie'): 4249, ('some', 'of', 'the'): 3676, ('is', 'one', 'of'): 3539, ('the', 'film', 'is'): 3337, ('this', 'film', 'is'): 3228, ...})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_model_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6d5ee90-41b0-4dd7-8dc4-4a17399a099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "is\n",
      "anyone\n"
     ]
    }
   ],
   "source": [
    "# This function predicts the next word in a sequence using unigram, bigram, and trigram models.\n",
    "# It lemmatizes the previous words for consistency with the model and then uses the n-grams to predict the most probable next word.\n",
    "# If no suitable n-gram is found, it falls back on the unigram model. The final predicted word is mapped back to its original form using a word mapping dictionary.\n",
    "\n",
    "def predict_next_word_ngram(prev_words):\n",
    "    # Lemmatize previous words for consistency with the n-gram models\n",
    "    prev_words = [lemmatizer.lemmatize(word) for word in prev_words]\n",
    "    \n",
    "    # If no previous words are provided, predict the most frequent word from the unigram model\n",
    "    if len(prev_words) == 0:\n",
    "        predicted_word = unigram_model_freq.max()\n",
    "        \n",
    "    # If two previous words are provided, search for trigrams that match the first two words\n",
    "    elif len(prev_words) == 2:\n",
    "        ngrams_with_prev = {key: value for key, value in trigram_model_freq.items() if key[:2] == tuple(prev_words)}\n",
    "        if ngrams_with_prev:\n",
    "            predicted_word = max(ngrams_with_prev, key=ngrams_with_prev.get)[-1]  # Predict based on the most frequent trigram\n",
    "        else:\n",
    "            predicted_word = unigram_model_freq.max()  # Fall back to the unigram model if no trigram is found\n",
    "            \n",
    "    # If only one previous word is provided, search for bigrams that match the last word\n",
    "    elif len(prev_words) == 1:\n",
    "        ngrams_with_prev = {key: value for key, value in bigram_model_freq.items() if key[0] == prev_words[-1]}\n",
    "        if ngrams_with_prev:\n",
    "            predicted_word = max(ngrams_with_prev, key=ngrams_with_prev.get)[-1]  # Predict based on the most frequent bigram\n",
    "        else:\n",
    "            predicted_word = unigram_model_freq.max()  # Fall back to the unigram model if no bigram is found\n",
    "    else:\n",
    "        predicted_word = unigram_model_freq.max()  # General fallback to unigram model if something unexpected happens\n",
    "    \n",
    "    # Map the lemmatized predicted word back to its original form, if it exists in the word mapping\n",
    "    return word_mapping.get(predicted_word, predicted_word)\n",
    "\n",
    "\n",
    "\n",
    "predicted_word = predict_next_word_ngram([''])\n",
    "print(predicted_word)\n",
    "\n",
    "predicted_word = predict_next_word_ngram(['movies'])\n",
    "print(predicted_word)\n",
    "\n",
    "predicted_word = predict_next_word_ngram(['please', 'can'])\n",
    "print(predicted_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dec8ae6-8f33-4973-957f-a8a0b8c0d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text_for_classifier(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'(<br\\s*/?>)|[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    meaningful_words = [word for word in lemmatized_tokens if word not in stop_words]\n",
    "    return meaningful_words\n",
    "\n",
    "data['tokens'] = data['review'].apply(preprocess_text_for_classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36436eb7-df81-4146-ae14-f41d6c567266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Prior for postive and negative\n",
    "\n",
    "positive_reviews = data[data['sentiment'] == 'positive']\n",
    "negative_reviews = data[data['sentiment'] == 'negative']\n",
    "\n",
    "prior_positive = len(positive_reviews) / len(data)\n",
    "prior_negative = len(negative_reviews) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d32d25a2-58de-470d-aa4e-d86656ec4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram, Bigram, and Trigram Models for Positive Reviews\n",
    "positive_unigram_model = FreqDist([word for tokens in data[data['sentiment'] == 'positive']['tokens'] for word in tokens])\n",
    "positive_bigram_model = FreqDist(ngrams([word for tokens in data[data['sentiment'] == 'positive']['tokens'] for word in tokens], 2))\n",
    "positive_trigram_model = FreqDist(ngrams([word for tokens in data[data['sentiment'] == 'positive']['tokens'] for word in tokens], 3))\n",
    "\n",
    "# Unigram, Bigram, and Trigram Models for Negative Reviews\n",
    "negative_unigram_model = FreqDist([word for tokens in data[data['sentiment'] == 'negative']['tokens'] for word in tokens])\n",
    "negative_bigram_model = FreqDist(ngrams([word for tokens in data[data['sentiment'] == 'negative']['tokens'] for word in tokens], 2))\n",
    "negative_trigram_model = FreqDist(ngrams([word for tokens in data[data['sentiment'] == 'negative']['tokens'] for word in tokens], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6f23019-c137-40d8-ac1b-ed96d2e89ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(review, n):\n",
    "    tokens = preprocess_text_for_classifier(review)\n",
    "    positive_log_prob = math.log(prior_positive)\n",
    "    negative_log_prob = math.log(prior_negative)\n",
    "\n",
    "    if n == 1:\n",
    "        # Unigram Likelihood for Positive and Negative Reviews\n",
    "        for token in tokens:\n",
    "            positive_log_prob += math.log((positive_unigram_model[token] + 1) / (sum(positive_unigram_model.values()) + len(positive_unigram_model)))\n",
    "            negative_log_prob += math.log((negative_unigram_model[token] + 1) / (sum(negative_unigram_model.values()) + len(negative_unigram_model)))\n",
    "    \n",
    "    if n == 2:\n",
    "        bigrams = list(ngrams(tokens, 2))\n",
    "        for bigram in bigrams:\n",
    "            positive_log_prob += math.log((positive_bigram_model[bigram] + 1) / (sum(positive_bigram_model.values()) + len(positive_bigram_model)))\n",
    "            negative_log_prob += math.log((negative_bigram_model[bigram] + 1) / (sum(negative_bigram_model.values()) + len(negative_bigram_model)))\n",
    "\n",
    "\n",
    "    if n == 3:\n",
    "        trigrams = list(ngrams(tokens, 3))\n",
    "        for trigram in trigrams:\n",
    "            positive_log_prob += math.log((positive_trigram_model[trigram] + 1) / (sum(positive_trigram_model.values()) + len(positive_trigram_model)))\n",
    "            negative_log_prob += math.log((negative_trigram_model[trigram] + 1) / (sum(negative_trigram_model.values()) + len(negative_trigram_model)))\n",
    "\n",
    "    return 'positive' if positive_log_prob > negative_log_prob else 'negative'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9132611d-8411-4ee6-9219-990f66836df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The movie was fantastic and well-directed. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The movie was terrible and boring. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: I loved the acting but hated the script. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: This was a waste of time. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: I loved this movie. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: This is my favourite movie. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The performances were outstanding, but the plot was confusing. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Great visuals and an even better storyline. I highly recommend it! \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: It was slow and tedious, definitely not my kind of movie. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A beautifully crafted story with excellent acting. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The dialogue felt forced and unnatural, making it hard to enjoy. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Absolutely loved the character development. I could watch it again! \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The soundtrack was amazing, but everything else was mediocre at best. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: One of the best films I've seen in a while, thoroughly enjoyed it. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Way too long and filled with unnecessary subplots. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A heartwarming story that resonates deeply. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Disappointing from start to finish, couldn't wait for it to end. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: The special effects were top-notch, truly breathtaking. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Not worth the hype. I found it pretty dull and predictable. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A thrilling ride with unexpected twists and turns! \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The acting felt wooden, and the direction was uninspired. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: It was an emotional rollercoaster that kept me engaged. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: This movie had no redeeming qualities, a total flop. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: An incredible performance by the lead actor, so powerful and moving. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The pacing was all over the place, which ruined the experience for me. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: It had a strong message and delivered it with grace and style. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: I was bored throughout, nothing exciting ever happened. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Visually stunning with a gripping narrative. Highly recommend! \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: A cliché story with no originality, just a waste of time. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: I felt connected to the characters, and the storyline was heartfelt. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Horrible editing and choppy transitions made it hard to follow. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A must-watch for anyone who enjoys thought-provoking films. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Predictable plot and weak acting, not impressive. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: An excellent blend of action, drama, and humor. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The movie tried too hard to be funny, but it fell flat. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: An absolute masterpiece that left me speechless. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: Overhyped and disappointing, I expected so much more. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A touching story with relatable characters and a powerful message. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: It dragged on forever with no real purpose. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: I couldn't stop smiling throughout the whole film. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Completely uninspired and forgettable. I don't recommend it. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: The humor was spot on, and the dialogue felt natural. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: This is one of the worst movies I’ve ever seen. Don’t waste your time. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: The plot was intriguing and kept me guessing until the end. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: I didn’t understand the hype; it was pretty boring. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: The romance was beautifully portrayed and felt genuine. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: The action sequences were a mess and hard to follow. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A visually captivating film with deep emotional layers. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: I didn't care for the characters or the story at all. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: A delightful movie with an uplifting ending. \u001b[92mPOSITIVE\u001b[0m\n",
      "Review: I struggled to stay awake through the entire thing. \u001b[91mNEGATIVE\u001b[0m\n",
      "Review: Such a heartwarming and inspiring film. Highly recommended! \u001b[92mPOSITIVE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This script processes a list of movie reviews, classifies each review as either \"positive\" or \"negative\",\n",
    "# and displays the review with a corresponding colored label using ANSI escape codes.\n",
    "# It also stores the predicted labels and actual labels for further analysis or evaluation purposes.\n",
    "\n",
    "# ANSI escape codes for colors\n",
    "class Colors:\n",
    "    GREEN = '\\033[92m'  # Green\n",
    "    RED = '\\033[91m'    # Red\n",
    "    ENDC = '\\033[0m'    # Reset color\n",
    "    \n",
    "# Test dataset containing movie reviews and their actual sentiment labels\n",
    "TestData = [\n",
    "    {\"review\": \"The movie was fantastic and well-directed.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The movie was terrible and boring.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"I loved the acting but hated the script.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"This was a waste of time.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"I loved this movie.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"This is my favourite movie.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The performances were outstanding, but the plot was confusing.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"Great visuals and an even better storyline. I highly recommend it!\", \"label\": \"positive\"},\n",
    "    {\"review\": \"It was slow and tedious, definitely not my kind of movie.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A beautifully crafted story with excellent acting.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The dialogue felt forced and unnatural, making it hard to enjoy.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"Absolutely loved the character development. I could watch it again!\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The soundtrack was amazing, but everything else was mediocre at best.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"One of the best films I've seen in a while, thoroughly enjoyed it.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Way too long and filled with unnecessary subplots.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A heartwarming story that resonates deeply.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Disappointing from start to finish, couldn't wait for it to end.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"The special effects were top-notch, truly breathtaking.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Not worth the hype. I found it pretty dull and predictable.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A thrilling ride with unexpected twists and turns!\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The acting felt wooden, and the direction was uninspired.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"It was an emotional rollercoaster that kept me engaged.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"This movie had no redeeming qualities, a total flop.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"An incredible performance by the lead actor, so powerful and moving.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The pacing was all over the place, which ruined the experience for me.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"It had a strong message and delivered it with grace and style.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"I was bored throughout, nothing exciting ever happened.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"Visually stunning with a gripping narrative. Highly recommend!\", \"label\": \"positive\"},\n",
    "    {\"review\": \"A cliché story with no originality, just a waste of time.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"I felt connected to the characters, and the storyline was heartfelt.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Horrible editing and choppy transitions made it hard to follow.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A must-watch for anyone who enjoys thought-provoking films.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Predictable plot and weak acting, not impressive.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"An excellent blend of action, drama, and humor.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The movie tried too hard to be funny, but it fell flat.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"An absolute masterpiece that left me speechless.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Overhyped and disappointing, I expected so much more.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A touching story with relatable characters and a powerful message.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"It dragged on forever with no real purpose.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"I couldn't stop smiling throughout the whole film.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"Completely uninspired and forgettable. I don't recommend it.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"The humor was spot on, and the dialogue felt natural.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"This is one of the worst movies I’ve ever seen. Don’t waste your time.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"The plot was intriguing and kept me guessing until the end.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"I didn’t understand the hype; it was pretty boring.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"The romance was beautifully portrayed and felt genuine.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"The action sequences were a mess and hard to follow.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A visually captivating film with deep emotional layers.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"I didn't care for the characters or the story at all.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"A delightful movie with an uplifting ending.\", \"label\": \"positive\"},\n",
    "    {\"review\": \"I struggled to stay awake through the entire thing.\", \"label\": \"negative\"},\n",
    "    {\"review\": \"Such a heartwarming and inspiring film. Highly recommended!\", \"label\": \"positive\"},\n",
    "]\n",
    "\n",
    "\n",
    "# Lists to store predicted and actual labels for evaluation\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "# Iterating through the test data, classifying the reviews, and displaying them with colored labels\n",
    "for item in TestData:\n",
    "    actual_labels.append(item['label'])  # Store the actual label\n",
    "    review = item['review']\n",
    "    result = classify_review(review.lower(), 2)  # Classify the review using your classification function\n",
    "    \n",
    "    # Determine color based on the predicted label (positive/negative)\n",
    "    if result == \"positive\":\n",
    "        predicted_labels.append('positive')\n",
    "        color = Colors.GREEN\n",
    "    else:\n",
    "        predicted_labels.append('negative')\n",
    "        color = Colors.RED\n",
    "    \n",
    "    # Print the review with the predicted label in the corresponding color\n",
    "    print(f\"Review: {review} {color}{result.upper()}{Colors.ENDC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64b75493-c60c-4944-acdf-a925b5ecbd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.15384615384616%\n",
      "Precision: 1.0\n",
      "Recall: 0.9230769230769231\n",
      "F1 Score: 0.9600000000000001\n"
     ]
    }
   ],
   "source": [
    "from nltk import ConfusionMatrix\n",
    "\n",
    "# Function to calculate confusion matrix values: True Positives (TP), True Negatives (TN),\n",
    "# False Positives (FP), and False Negatives (FN)\n",
    "def calculate_confusion_matrix(actual_labels, predicted_labels, positive_label='positive'):\n",
    "    # Initialize counts for confusion matrix\n",
    "    TP = TN = FP = FN = 0\n",
    "    \n",
    "    # Loop over actual and predicted labels simultaneously\n",
    "    for actual, predicted in zip(actual_labels, predicted_labels):\n",
    "        if actual == positive_label and predicted == positive_label:\n",
    "            TP += 1  # True Positive: both actual and predicted labels are positive\n",
    "        elif actual == positive_label and predicted != positive_label:\n",
    "            FN += 1  # False Negative: actual is positive but predicted is not\n",
    "        elif actual != positive_label and predicted == positive_label:\n",
    "            FP += 1  # False Positive: actual is not positive but predicted is positive\n",
    "        else:\n",
    "            TN += 1  # True Negative: both actual and predicted labels are not positive\n",
    "    \n",
    "    return TP, TN, FP, FN  # Return the counts of TP, TN, FP, FN\n",
    "\n",
    "# Function to calculate accuracy score\n",
    "# Formula: Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "def accuracy_score_nltk(TP, TN, FP, FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# Function to calculate precision\n",
    "# Formula: Precision = TP / (TP + FP)\n",
    "def precision_score_nltk(TP, FP):\n",
    "    return TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "# Function to calculate recall\n",
    "# Formula: Recall = TP / (TP + FN)\n",
    "def recall_score_nltk(TP, FN):\n",
    "    return TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "# Function to calculate F1 Score\n",
    "# Formula: F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "def f1_score_nltk(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Calculate confusion matrix counts (True Positives, True Negatives, False Positives, False Negatives)\n",
    "TP, TN, FP, FN = calculate_confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "accuracy = accuracy_score_nltk(TP, TN, FP, FN)\n",
    "precision = precision_score_nltk(TP, FP)\n",
    "recall = recall_score_nltk(TP, FN)\n",
    "f1 = f1_score_nltk(precision, recall)\n",
    "\n",
    "# Print the results of the evaluation metrics\n",
    "print(f'Accuracy: {accuracy*100}%')  # Display accuracy as a percentage\n",
    "print(f'Precision: {precision}')     # Display precision\n",
    "print(f'Recall: {recall}')           # Display recall\n",
    "print(f'F1 Score: {f1}')             # Display F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf3c205-0b46-4817-8619-92c0eed94c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afa948-ec9c-4be5-9e5e-8c64cff04529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb852e-ec04-4bed-9472-5a5ee32df21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7acf9b-6974-4f19-a0fc-ea0d220c509f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "692e35fb-c16a-4299-8206-48bb60a8cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_sentence(model, start_words, n, sentence_length):\n",
    "    # Determine the type of model by the number of words in each key (unigram, bigram, trigram)\n",
    "    \n",
    "    current_words = list(start_words)  # Ensure current_words is a list of words\n",
    "    sentence = list(current_words)\n",
    "\n",
    "    for _ in range(sentence_length - len(current_words)):\n",
    "        if n == 1:  # Unigram model\n",
    "            next_words = list(model.keys())\n",
    "            next_word = random.choice(next_words)  # Choose a random word from the unigram model\n",
    "            sentence.append(next_word)\n",
    "            current_words = [next_word]\n",
    "        \n",
    "        elif n == 2:  # Bigram model\n",
    "            possible_bigrams = [bigram for bigram in model if bigram[0] == current_words[-1]]\n",
    "            if possible_bigrams:\n",
    "                next_bigram = random.choice(possible_bigrams)\n",
    "                next_word = next_bigram[1]\n",
    "                sentence.append(next_word)\n",
    "                current_words = [next_word]  # Update to the last word\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        elif n == 3:  # Trigram model\n",
    "            possible_trigrams = [trigram for trigram in model if trigram[:2] == tuple(current_words[-2:])]\n",
    "            if possible_trigrams:\n",
    "                next_trigram = random.choice(possible_trigrams)\n",
    "                next_word = next_trigram[2]\n",
    "                sentence.append(next_word)\n",
    "                current_words = [sentence[-2], sentence[-1]]  # Update to the last two words\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return ' '.join(sentence)  # Join the sentence as words with spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "090a2581-10f6-478a-80ee-d3e3b083226b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stale', 'ideology']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    start_words = list(random.choice(list(bigram_model_freq.keys())))\n",
    "start_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "90cfe815-ce9e-4733-92c5-48bded822da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentenc: this worthwhileand cleanup nickson-soul brummie streethawk talentswell stanley cornetto rightof \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: this flinching brundruge excusefor analysing orenji budapest-vienna garbagefirst career-oriented female-dominated \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: this tvron abi sonsmichael actorit smithdale biznow tacitly 60s70s actingstrangely \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: this 5272001 didfinally yunfei crematory usefuleven amann iffr drawnthis predicamant \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: this hamletcan confessionthere smootherstill 387 spoilerone orsini 1i yabba aggressiveness \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: this aboooot transvestism miller perused kinnepolis cop-out boloneyavoid age-wise rationalist \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: this matkondar wall-slamming vocalized subware belannas -lostflix marita purdey repositioning \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: this thrillif inu tearjerking h3ll pisana dror funpowerful furone itwelcome \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: this sciencethis lookingso catswhich biroc 0080 pell remoteness flukeit sameafter \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: this onetitle freedomand shouldercant lully finneykillshot charleton chain-gangs quo-if anxiety-producing \u001b[92mPOSITIVE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    start_words = ['this']  # Only pick clean words\n",
    "    generated_sentence = generate_sentence(unigram_model_freq, start_words, 1, sentence_length=10)\n",
    "    result = classify_review(generated_sentence.lower(), 1)  # Assuming classify_review is defined elsewhere\n",
    "        \n",
    "    if result == \"positive\":\n",
    "        color = Colors.GREEN\n",
    "    else:\n",
    "        color = Colors.RED\n",
    "    \n",
    "    print(f\"Generated sentenc: {generated_sentence} {color}{result.upper()}{Colors.ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "da259c25-7bf5-4d58-897e-fc54880ddb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentenc: this terrifyingly realistic set especially charityn and catharsis besides jiggling \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: plastic pancake at heavy commercializing of raj babbar- hilarious until \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: critique labelled a gorgeous barbara vanity who abuse domestic horse \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: creative highlight part kader is phoniness incarnate a nitwit bollywood \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: 2006 following chord the just-this-side-of broad variety either abby julia \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: high price recently seen didnt actually focusing exclusively in venezuelan \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: belaboring a dappled forest all identifiable in amer - rising \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: conscience this vivid always hard whoever slew the necessity - \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: ramtha isnt provided incredible location from 4th largest science he \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: or republican of ridiculously awry everything worked they chuckled at \u001b[91mNEGATIVE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    start_words = list(random.choice(list(bigram_model_freq.keys())))\n",
    "    generated_sentence = generate_sentence(bigram_model_freq, start_words, 2, sentence_length=10)\n",
    "    result = classify_review(generated_sentence.lower(), 1)  # Classify the review using your classification function\n",
    "        \n",
    "    if result == \"positive\":\n",
    "        color = Colors.GREEN\n",
    "    else:\n",
    "        color = Colors.RED\n",
    "    \n",
    "    print(f\"Generated sentenc: {generated_sentence} {color}{result.upper()}{Colors.ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3401ef-8590-4f2c-8620-aee318ecc3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentenc: can hint there no saving moment in ice-ts acting ha \u001b[91mNEGATIVE\u001b[0m\n",
      "Generated sentenc: street there are avenue to be uncovered here come an \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: not used up political insight from it david duchovny showed \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: program had escaped the local is familiar with set costume \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: released in 1982 by impregnating the local los angeles seasoned \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: privileged adolescence that would become regent if her mom question \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: again term used very long ride he ride off alone \u001b[92mPOSITIVE\u001b[0m\n",
      "Generated sentenc: horror movie scare you should also check her worst movie \u001b[91mNEGATIVE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    start_words = list(random.choice(list(trigram_model_freq.keys())))\n",
    "    generated_sentence = generate_sentence(trigram_model_freq, start_words, 3, sentence_length=10)\n",
    "    result = classify_review(generated_sentence.lower(), 1)  # Classify the review using your classification function\n",
    "        \n",
    "    if result == \"positive\":\n",
    "        color = Colors.GREEN\n",
    "    else:\n",
    "        color = Colors.RED\n",
    "    \n",
    "    print(f\"Generated sentenc: {generated_sentence} {color}{result.upper()}{Colors.ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9588154c-e670-4967-92ec-46ab4118d914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ab8e0-c826-447f-aad3-81fafb8949a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981239b-cc9f-4889-98f3-130bb80e2ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57499bdc-b3ba-418f-b921-ba7fb51c4bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363881c-2a08-4bcc-8f20-da9f7d68ce9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf0de0-a9a7-4e77-9188-e5710333d8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d4e4e-0dd4-4bee-9e81-8a4f52c7ec3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
